{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying realtime inference with API requests\n",
    "\n",
    "By Daniel Marostica\n",
    "\n",
    "### Predict if somebody would or not survive the sinking of RMS Titanic creating and invoking a SageMaker endpoint. \n",
    "\n",
    "In this example, we use SageMaker's Script Mode, in which you need to provide proper in/output functions so that everything is plugged in correctly. More information inside the python files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import joblib\n",
    "\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket() # create a bucket or use your account's default\n",
    "prefix = 'titanic_realtime' # folder name to store your input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading the data for training <a class='anchor' id='upload_data'></a>\n",
    "\n",
    "When in production, with large amounts of data, you can use Amazon Athena, AWS Glue or Amazon EMR to store data in S3. We will use the SageMaker Python SDK to upload the data to a default bucket.\n",
    "\n",
    "`train_input` contains the S3 path to the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = sagemaker_session.upload_data(\n",
    "    path='titanic.csv',\n",
    "    bucket=bucket,\n",
    "    key_prefix='{}/{}'.format(prefix, 'train'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SageMaker Scikit Estimator <a class='anchor' id='create_sklearn_estimator'></a>\n",
    "\n",
    "I have developed a code (`preprocessing.py`) to preprocess data which contains an SKLearn model that has to be fitted.\n",
    "SageMaker will start an instance and fit it for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "FRAMEWORK_VERSION = '0.23-1' # sklearn version\n",
    "script_path = 'preprocessing.py'\n",
    "\n",
    "sklearn_preprocessor = SKLearn(\n",
    "    entry_point=script_path,\n",
    "    role=role,\n",
    "    framework_version=FRAMEWORK_VERSION,\n",
    "    instance_type='ml.c4.xlarge',\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-07 12:14:00 Starting - Starting the training job...\n",
      "2021-12-07 12:14:26 Starting - Launching requested ML instancesProfilerReport-1638879240: InProgress\n",
      "......\n",
      "2021-12-07 12:15:26 Starting - Preparing the instances for training.........\n",
      "2021-12-07 12:16:47 Downloading - Downloading input data...\n",
      "2021-12-07 12:17:27 Training - Downloading the training image..\u001b[34m2021-12-07 12:17:36,034 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2021-12-07 12:17:36,037 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-12-07 12:17:36,051 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\n",
      "2021-12-07 12:17:56 Uploading - Uploading generated training model\u001b[34m2021-12-07 12:17:50,092 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-12-07 12:17:50,105 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-12-07 12:17:50,119 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-12-07 12:17:50,129 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2021-12-07-12-14-00-280\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-296025910508/sagemaker-scikit-learn-2021-12-07-12-14-00-280/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"preprocessing\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"preprocessing.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=preprocessing.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=preprocessing\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-296025910508/sagemaker-scikit-learn-2021-12-07-12-14-00-280/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2021-12-07-12-14-00-280\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-296025910508/sagemaker-scikit-learn-2021-12-07-12-14-00-280/source/sourcedir.tar.gz\",\"module_name\":\"preprocessing\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"preprocessing.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python preprocessing.py\u001b[0m\n",
      "\u001b[34mReading input data from /opt/ml/input/data/train/titanic.csv\u001b[0m\n",
      "\u001b[34m2021-12-07 12:17:52,108 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-12-07 12:18:27 Completed - Training job completed\n",
      "ProfilerReport-1638879240: NoIssuesFound\n",
      "Training seconds: 76\n",
      "Billable seconds: 76\n"
     ]
    }
   ],
   "source": [
    "sklearn_preprocessor.fit({'train': train_input}) # 'train' is the name of the channel set in preprocessing.py's args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform training data <a class='anchor' id='preprocess_train_data'></a>\n",
    "After the preprocessor is properly fitted, the training data has to be transformed. SageMaker will create another instance and apply with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = sklearn_preprocessor.transformer(\n",
    "    instance_count=1, instance_type='ml.m5.xlarge', assemble_with='Line', accept='text/csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................\u001b[34m2021-12-07 12:23:27,232 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-12-07 12:23:27,235 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-12-07 12:23:27,235 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2021-12-07 12:23:27,427 INFO - sagemaker-containers - Module preprocessing does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2021-12-07 12:23:27,427 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2021-12-07 12:23:27,428 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2021-12-07 12:23:27,428 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: preprocessing\n",
      "  Building wheel for preprocessing (setup.py): started\n",
      "  Building wheel for preprocessing (setup.py): finished with status 'done'\n",
      "  Created wheel for preprocessing: filename=preprocessing-1.0.0-py2.py3-none-any.whl size=5548 sha256=0f26fd58a896564484fe447f5ae53ec17f4c7329e9398174dcc82be273ffaee7\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-doovxjht/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[34mSuccessfully built preprocessing\u001b[0m\n",
      "\u001b[34mInstalling collected packages: preprocessing\u001b[0m\n",
      "\u001b[34mSuccessfully installed preprocessing-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/miniconda3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m[2021-12-07 12:23:29 +0000] [37] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2021-12-07 12:23:29 +0000] [37] [INFO] Listening at: unix:/tmp/gunicorn.sock (37)\u001b[0m\n",
      "\u001b[34m[2021-12-07 12:23:29 +0000] [37] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-12-07 12:23:29 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2021-12-07 12:23:29 +0000] [41] [INFO] Booting worker with pid: 41\u001b[0m\n",
      "\u001b[34m[2021-12-07 12:23:29 +0000] [42] [INFO] Booting worker with pid: 42\u001b[0m\n",
      "\u001b[34m[2021-12-07 12:23:29 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[34m2021-12-07 12:23:32,039 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [07/Dec/2021:12:23:32 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [07/Dec/2021:12:23:32 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2021-12-07 12:23:32,576 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [07/Dec/2021:12:23:33 +0000] \"POST /invocations HTTP/1.1\" 200 121344 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\n",
      "\u001b[32m2021-12-07T12:23:32.550:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "Waiting for transform job: sagemaker-scikit-learn-2021-12-07-12-18-44-092\n",
      "\u001b[34m2021-12-07 12:23:27,232 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-12-07 12:23:27,235 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-12-07 12:23:27,235 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2021-12-07 12:23:27,427 INFO - sagemaker-containers - Module preprocessing does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2021-12-07 12:23:27,427 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2021-12-07 12:23:27,428 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2021-12-07 12:23:27,428 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[35m2021-12-07 12:23:27,232 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-12-07 12:23:27,235 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-12-07 12:23:27,235 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m2021-12-07 12:23:27,427 INFO - sagemaker-containers - Module preprocessing does not provide a setup.py. \u001b[0m\n",
      "\u001b[35mGenerating setup.py\u001b[0m\n",
      "\u001b[35m2021-12-07 12:23:27,427 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
      "\u001b[35m2021-12-07 12:23:27,428 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
      "\u001b[35m2021-12-07 12:23:27,428 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: preprocessing\n",
      "  Building wheel for preprocessing (setup.py): started\n",
      "  Building wheel for preprocessing (setup.py): finished with status 'done'\n",
      "  Created wheel for preprocessing: filename=preprocessing-1.0.0-py2.py3-none-any.whl size=5548 sha256=0f26fd58a896564484fe447f5ae53ec17f4c7329e9398174dcc82be273ffaee7\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-doovxjht/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[34mSuccessfully built preprocessing\u001b[0m\n",
      "\u001b[34mInstalling collected packages: preprocessing\u001b[0m\n",
      "\u001b[34mSuccessfully installed preprocessing-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/miniconda3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[35m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[35mProcessing /opt/ml/code\n",
      "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: preprocessing\n",
      "  Building wheel for preprocessing (setup.py): started\n",
      "  Building wheel for preprocessing (setup.py): finished with status 'done'\n",
      "  Created wheel for preprocessing: filename=preprocessing-1.0.0-py2.py3-none-any.whl size=5548 sha256=0f26fd58a896564484fe447f5ae53ec17f4c7329e9398174dcc82be273ffaee7\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-doovxjht/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[35mSuccessfully built preprocessing\u001b[0m\n",
      "\u001b[35mInstalling collected packages: preprocessing\u001b[0m\n",
      "\u001b[35mSuccessfully installed preprocessing-1.0.0\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\u001b[0m\n",
      "\u001b[35mYou should consider upgrading via the '/miniconda3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m[2021-12-07 12:23:29 +0000] [37] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2021-12-07 12:23:29 +0000] [37] [INFO] Listening at: unix:/tmp/gunicorn.sock (37)\u001b[0m\n",
      "\u001b[34m[2021-12-07 12:23:29 +0000] [37] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-12-07 12:23:29 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[34m[2021-12-07 12:23:29 +0000] [41] [INFO] Booting worker with pid: 41\u001b[0m\n",
      "\u001b[34m[2021-12-07 12:23:29 +0000] [42] [INFO] Booting worker with pid: 42\u001b[0m\n",
      "\u001b[34m[2021-12-07 12:23:29 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[35m[2021-12-07 12:23:29 +0000] [37] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2021-12-07 12:23:29 +0000] [37] [INFO] Listening at: unix:/tmp/gunicorn.sock (37)\u001b[0m\n",
      "\u001b[35m[2021-12-07 12:23:29 +0000] [37] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-12-07 12:23:29 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
      "\u001b[35m[2021-12-07 12:23:29 +0000] [41] [INFO] Booting worker with pid: 41\u001b[0m\n",
      "\u001b[35m[2021-12-07 12:23:29 +0000] [42] [INFO] Booting worker with pid: 42\u001b[0m\n",
      "\u001b[35m[2021-12-07 12:23:29 +0000] [46] [INFO] Booting worker with pid: 46\u001b[0m\n",
      "\u001b[34m2021-12-07 12:23:32,039 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2021-12-07 12:23:32,039 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [07/Dec/2021:12:23:32 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [07/Dec/2021:12:23:32 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2021-12-07 12:23:32,576 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [07/Dec/2021:12:23:33 +0000] \"POST /invocations HTTP/1.1\" 200 121344 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [07/Dec/2021:12:23:32 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [07/Dec/2021:12:23:32 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2021-12-07 12:23:32,576 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [07/Dec/2021:12:23:33 +0000] \"POST /invocations HTTP/1.1\" 200 121344 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2021-12-07T12:23:32.550:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-296025910508/sagemaker-scikit-learn-2021-12-07-12-18-44-092'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.transform(train_input, content_type='text/csv')\n",
    "transformer.wait()\n",
    "\n",
    "preprocessed_train = transformer.output_path # save preprocessed data path\n",
    "preprocessed_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Random Forest model with preprocessed data <a class='anchor' id='training_model'></a>\n",
    "\n",
    "Now the data can be fit by, for example, a Random Forest Classifier, which I wrote in `inference.py`. It is a Scikit-Learn model, so it's required to invoke SageMaker's SKLearn constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "sklearn = SKLearn(\n",
    "    entry_point='inference.py',\n",
    "    framework_version='0.23-1',\n",
    "    instance_type='ml.m5.large',\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={\"max_leaf_nodes\": 30},\n",
    "    base_job_name='sm-training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-07 12:23:59 Starting - Starting the training job...\n",
      "2021-12-07 12:24:29 Starting - Launching requested ML instancesProfilerReport-1638879839: InProgress\n",
      "......\n",
      "2021-12-07 12:25:29 Starting - Preparing the instances for training............\n",
      "2021-12-07 12:27:30 Downloading - Downloading input data\n",
      "2021-12-07 12:27:30 Training - Downloading the training image...\n",
      "2021-12-07 12:28:01 Uploading - Uploading generated training model.\u001b[34m2021-12-07 12:27:50,824 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2021-12-07 12:27:50,826 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-12-07 12:27:50,836 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-12-07 12:27:51,101 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-12-07 12:27:54,124 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-12-07 12:27:54,138 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-12-07 12:27:54,147 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"max_leaf_nodes\": 30\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sm-training-2021-12-07-12-23-59-285\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-296025910508/sm-training-2021-12-07-12-23-59-285/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"inference\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"inference.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"max_leaf_nodes\":30}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=inference.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=inference\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-296025910508/sm-training-2021-12-07-12-23-59-285/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"max_leaf_nodes\":30},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sm-training-2021-12-07-12-23-59-285\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-296025910508/sm-training-2021-12-07-12-23-59-285/source/sourcedir.tar.gz\",\"module_name\":\"inference\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"inference.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--max_leaf_nodes\",\"30\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_LEAF_NODES=30\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python inference.py --max_leaf_nodes 30\u001b[0m\n",
      "\u001b[34m2021-12-07 12:27:55,865 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-12-07 12:28:30 Completed - Training job completed\n",
      "Training seconds: 67\n",
      "Billable seconds: 67\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sm-training-2021-12-07-12-23-59-285'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.fit({'train': preprocessed_train})\n",
    "\n",
    "training_job_name = sklearn._current_job_name\n",
    "training_job_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the inference pipeline <a class='anchor' id='pipeline_setup'></a>\n",
    "\n",
    "We need a pipeline with two steps: preprocessing and inference. That is why we import PipelineModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.pipeline import PipelineModel\n",
    "from time import gmtime, strftime\n",
    "\n",
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()) # get current time to name the model and the endpoint\n",
    "\n",
    "scikit_learn_preprocess = sklearn_preprocessor.create_model() # create a model with our transformer\n",
    "random_forest = sklearn.create_model() # create a model with our SKLearn constructor instanced object\n",
    "\n",
    "model_name = 'inference-pipeline-titanic-' + timestamp_prefix\n",
    "endpoint_name = 'inference-pipeline-ep-titanic-' + timestamp_prefix\n",
    "\n",
    "sm_model = PipelineModel(\n",
    "    name=model_name, role=role, models=[scikit_learn_preprocess, random_forest])\n",
    "\n",
    "sm_model.deploy(initial_instance_count=1, instance_type='ml.c4.xlarge', endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inference-pipeline-ep-titanic-2021-12-07-12-28-42'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a request to our pipeline endpoint <a class='anchor' id='pipeline_inference_request'></a>\n",
    "\n",
    "After the endpoint has been deployed, we can make requests of inference, in realtime. I'll demonstrate both a CSV and a JSON example.\n",
    "\n",
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age,Embarked,Fare,Parch,Pclass,Sex,SibSp,Family_Size\n",
      "22.0,S,7.25,0,3,male,1,1\n",
      "b'{\"instances\": [0.0]}'\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "payload = 'Age,Embarked,Fare,Parch,Pclass,Sex,SibSp,Family_Size\\n22.0,S,7.25,0,3,male,1,1'\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name, \n",
    "    sagemaker_session=sagemaker_session, \n",
    "    serializer=CSVSerializer())\n",
    "\n",
    "predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"instances\": [0.0]}'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "payload = '[{\"Age\":22,\"Embarked\":\"S\",\"Fare\":7.25,\"Parch\":0,\"Pclass\":3,\"Sex\":\"male\",\"SibSp\":1,\"Family_Size\":1}]'\n",
    "\n",
    "client=boto3.client('sagemaker-runtime')\n",
    "response=client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=payload,\n",
    "    ContentType='application/json')\n",
    "\n",
    "response.get('Body').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the endpoint instance had returned 1.0, the person would probably have survived. It has returned 0.0, so, bad news.\n",
    "\n",
    "In this example, I made the request with only one line. If you send more data for inference, the instance will return a list with all the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLI request\n",
    "\n",
    "Alternatively, you can invoke the endpoint through command line interface:\n",
    "\n",
    "```\n",
    "aws sagemaker-runtime invoke-endpoint \\\n",
    "  --endpoint-name inference-pipeline-ep-titanic-2021-12-07-12-28-42 \\\n",
    "  --body fileb://test.json \\\n",
    "  --content-type application/json \\\n",
    "  --accept application/json \\\n",
    "  output_file.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Endpoint <a class='anchor' id='delete_endpoint'></a>\n",
    "\n",
    "Easily delete the endpoint if you are not using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = sagemaker_session.boto_session.client('sagemaker')\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
